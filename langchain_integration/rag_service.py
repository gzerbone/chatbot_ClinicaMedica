"""
LangChain RAG Service - Fase 1
Servi√ßo RAG otimizado usando LangChain
"""
import json
import logging
import os
from typing import Any, Dict, List, Optional

from django.conf import settings
from django.core.cache import cache
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document
from langchain_core.retrievers import BaseRetriever
from langchain_core.vectorstores import VectorStore
from langchain_google_genai import GoogleGenerativeAIEmbeddings

from rag_agent.models import (ClinicaInfo, Convenio, Especialidade, Exame,
                              Medico)

from .config import LANGCHAIN_CONFIG, RAG_CONFIG

logger = logging.getLogger(__name__)


class LangChainRAGService:
    """
    Servi√ßo RAG otimizado usando LangChain
    
    Responsabilidades:
    1. Criar e gerenciar vector store
    2. Indexar dados da cl√≠nica
    3. Realizar buscas sem√¢nticas
    4. Cache inteligente
    """
    
    def __init__(self):
        self.embeddings = None
        self.vectorstore = None
        self._initialize_embeddings()
        self._load_or_create_vectorstore()
    
    def _initialize_embeddings(self):
        """Inicializa embeddings do Google"""
        try:
            self.embeddings = GoogleGenerativeAIEmbeddings(
                model=LANGCHAIN_CONFIG['EMBEDDING_MODEL'],
                google_api_key=LANGCHAIN_CONFIG['GEMINI_API_KEY']
            )
            logger.info("‚úÖ Embeddings Google inicializados com sucesso")
        except Exception as e:
            logger.error(f"‚ùå Erro ao inicializar embeddings: {e}")
            self.embeddings = None
    
    def _load_or_create_vectorstore(self):
        """Carrega ou cria vector store"""
        try:
            vectorstore_path = LANGCHAIN_CONFIG['VECTOR_STORE_PATH']
            
            # Criar diret√≥rio se n√£o existir
            os.makedirs(vectorstore_path, exist_ok=True)
            
            # Tentar carregar vector store existente
            if os.path.exists(os.path.join(vectorstore_path, "index.faiss")):
                self.vectorstore = FAISS.load_local(
                    vectorstore_path, 
                    self.embeddings,
                    allow_dangerous_deserialization=True
                )
                logger.info("‚úÖ Vector store carregado com sucesso")
            else:
                # Criar novo vector store
                self._create_vectorstore()
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao carregar/criar vector store: {e}")
            self.vectorstore = None
    
    def _create_vectorstore(self):
        """Cria novo vector store com dados da cl√≠nica"""
        try:
            # Coletar todos os dados da cl√≠nica
            documents = self._collect_clinic_documents()
            
            if not documents:
                logger.warning("‚ö†Ô∏è Nenhum documento encontrado para criar vector store")
                return
            
            # Criar vector store
            self.vectorstore = FAISS.from_documents(
                documents, 
                self.embeddings
            )
            
            # Salvar vector store
            vectorstore_path = LANGCHAIN_CONFIG['VECTOR_STORE_PATH']
            self.vectorstore.save_local(vectorstore_path)
            
            logger.info(f"‚úÖ Vector store criado com {len(documents)} documentos")
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao criar vector store: {e}")
            self.vectorstore = None
    
    def _collect_clinic_documents(self) -> List[Document]:
        """Coleta todos os dados da cl√≠nica em formato Document"""
        documents = []
        
        try:
            # Informa√ß√µes da cl√≠nica
            clinica = ClinicaInfo.objects.first()
            if clinica:
                doc = Document(
                    page_content=f"""
                    Informa√ß√µes da Cl√≠nica:
                    Nome: {clinica.nome}
                    Secret√°ria: {clinica.secretaria_nome}
                    Endere√ßo: {clinica.endereco}
                    Telefone: {clinica.telefone_contato}
                    WhatsApp: {clinica.whatsapp_contato}
                    Hor√°rio de Funcionamento: {clinica.horario_funcionamento}
                    Objetivo Geral da Cl√≠nica: {clinica.objetivo_geral}
                    """,
                    metadata={
                        "type": "clinica_info",
                        "id": clinica.id,
                        "source": "clinica"
                    }
                )
                documents.append(doc)
            
            # M√©dicos
            medicos = Medico.objects.prefetch_related('especialidades', 'convenios')
            for medico in medicos:
                especialidades = ", ".join([esp.nome for esp in medico.especialidades.all()])
                convenios = ", ".join([conv.nome for conv in medico.convenios.all()])
                
                doc = Document(
                    page_content=f"""
                    M√©dico: {medico.nome}
                    CRM do {medico.nome}: {medico.crm}
                    Especialidades de {medico.nome}: {especialidades}
                    Conv√™nios Aceito por {medico.nome}: {convenios}
                    Pre√ßo Particular: R$ {medico.preco_particular}
                    Formas de Pagamento: {medico.formas_pagamento}
                    Retorno Info: {medico.retorno_info}
                    Descri√ß√£o do {medico.nome}: {medico.bio}
                    """,
                    metadata={
                        "type": "medico",
                        "id": medico.id,
                        "nome": medico.nome,
                        "crm": medico.crm,
                        "especialidades": [esp.nome for esp in medico.especialidades.all()],
                        "source": "medicos"
                    }
                )
                documents.append(doc)
            
            # Especialidades
            especialidades = Especialidade.objects.filter(ativa=True)
            for esp in especialidades:
                doc = Document(
                    page_content=f"""
                    Especialidade: {esp.nome}
                    Descri√ß√£o: {esp.descricao}
                    Ativa: {esp.ativa}
                    """,
                    metadata={
                        "type": "especialidade",
                        "id": esp.id,
                        "nome": esp.nome,
                        "source": "especialidades"
                    }
                )
                documents.append(doc)
            
            # Exames
            exames = Exame.objects.all()
            for exame in exames:
                doc = Document(
                    page_content=f"""
                    Exame: {exame.nome}
                    Descri√ß√£o: {exame.o_que_e}
                    Como Funciona: {exame.como_funciona}
                    Pre√ßo: R$ {exame.preco}
                    Dura√ß√£o: {exame.duracao_estimada}
                    Prepara√ß√£o: {exame.preparacao}
                    Vantagem: {exame.vantagem}
                    """,
                    metadata={
                        "type": "exame",
                        "id": exame.id,
                        "nome": exame.nome,
                        "preco": str(exame.preco),
                        "source": "exames"
                    }
                )
                documents.append(doc)
            
            # Conv√™nios
            convenios = Convenio.objects.all()
            for convenio in convenios:
                doc = Document(
                    page_content=f"""
                    Conv√™nio: {convenio.nome}
                    Descri√ß√£o: {convenio.descricao}
                    """,
                    metadata={
                        "type": "convenio",
                        "id": convenio.id,
                        "nome": convenio.nome,
                        "source": "convenios"
                    }
                )
                documents.append(doc)
            
            logger.info(f"üìö Coletados {len(documents)} documentos da cl√≠nica")
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao coletar documentos: {e}")
        
        return documents
    
    def search(self, query: str, k: int = None) -> List[Dict[str, Any]]:
        """
        Busca sem√¢ntica no vector store
        
        Args:
            query: Consulta de busca
            k: N√∫mero de resultados (padr√£o: RAG_CONFIG['K_RETRIEVAL'])
            
        Returns:
            Lista de documentos relevantes
        """
        if not self.vectorstore:
            logger.warning("‚ö†Ô∏è Vector store n√£o dispon√≠vel")
            return []
        
        try:
            k = k or RAG_CONFIG['K_RETRIEVAL']
            
            # Buscar documentos similares
            docs = self.vectorstore.similarity_search_with_score(
                query, 
                k=k
            )
            
            # Filtrar por threshold de similaridade
            threshold = RAG_CONFIG['SIMILARITY_THRESHOLD']
            filtered_docs = [
                {
                    'content': doc.page_content,
                    'metadata': doc.metadata,
                    'score': score,
                    'relevance': 'high' if score > 0.8 else 'medium' if score > 0.6 else 'low'
                }
                for doc, score in docs
                if score >= threshold
            ]
            
            logger.info(f"üîç Busca '{query}' retornou {len(filtered_docs)} resultados")
            return filtered_docs
            
        except Exception as e:
            logger.error(f"‚ùå Erro na busca: {e}")
            return []
    
    def get_clinic_info(self, query: str = None) -> Dict[str, Any]:
        """
        Obt√©m informa√ß√µes da cl√≠nica
        
        Args:
            query: Consulta espec√≠fica (opcional)
            
        Returns:
            Informa√ß√µes da cl√≠nica
        """
        cache_key = f"langchain_clinic_info_{query or 'all'}"
        cached_data = cache.get(cache_key)
        
        if cached_data:
            return cached_data
        
        try:
            if query:
                # Busca sem√¢ntica
                results = self.search(query, k=3)
                clinic_docs = [r for r in results if r['metadata'].get('type') == 'clinica_info']
                
                if clinic_docs:
                    return {
                        'content': clinic_docs[0]['content'],
                        'metadata': clinic_docs[0]['metadata'],
                        'relevance': clinic_docs[0]['relevance']
                    }
            
            # Fallback: dados diretos do banco
            clinica = ClinicaInfo.objects.first()
            if clinica:
                from rag_agent.serializers import ClinicaInfoSerializer
                data = ClinicaInfoSerializer(clinica).data
                cache.set(cache_key, data, LANGCHAIN_CONFIG['CACHE_TTL'])
                return data
            
            return {}
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao obter informa√ß√µes da cl√≠nica: {e}")
            return {}
    
    def get_doctors(self, query: str = None, specialty: str = None) -> List[Dict[str, Any]]:
        """
        Obt√©m m√©dicos com busca sem√¢ntica
        
        Args:
            query: Consulta de busca
            specialty: Especialidade espec√≠fica
            
        Returns:
            Lista de m√©dicos
        """
        cache_key = f"langchain_doctors_{query or 'all'}_{specialty or 'all'}"
        cached_data = cache.get(cache_key)
        
        if cached_data:
            return cached_data
        
        try:
            if query:
                # Busca sem√¢ntica
                results = self.search(query, k=5)
                doctor_docs = [r for r in results if r['metadata'].get('type') == 'medico']
                
                if doctor_docs:
                    doctors = []
                    for doc in doctor_docs:
                        doctors.append({
                            'content': doc['content'],
                            'metadata': doc['metadata'],
                            'relevance': doc['relevance']
                        })
                    
                    cache.set(cache_key, doctors, LANGCHAIN_CONFIG['CACHE_TTL'])
                    return doctors
            
            # Fallback: dados diretos do banco
            medicos = Medico.objects.prefetch_related('especialidades', 'convenios')
            if specialty:
                medicos = medicos.filter(especialidades__nome__icontains=specialty)
            
            from rag_agent.serializers import MedicoResumoSerializer
            data = MedicoResumoSerializer(medicos, many=True).data
            cache.set(cache_key, data, LANGCHAIN_CONFIG['CACHE_TTL'])
            return data
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao obter m√©dicos: {e}")
            return []
    
    def get_exams(self, query: str = None) -> List[Dict[str, Any]]:
        """
        Obt√©m exames com busca sem√¢ntica
        
        Args:
            query: Consulta de busca
            
        Returns:
            Lista de exames
        """
        cache_key = f"langchain_exams_{query or 'all'}"
        cached_data = cache.get(cache_key)
        
        if cached_data:
            return cached_data
        
        try:
            if query:
                # Busca sem√¢ntica
                results = self.search(query, k=5)
                exam_docs = [r for r in results if r['metadata'].get('type') == 'exame']
                
                if exam_docs:
                    exams = []
                    for doc in exam_docs:
                        exams.append({
                            'content': doc['content'],
                            'metadata': doc['metadata'],
                            'relevance': doc['relevance']
                        })
                    
                    cache.set(cache_key, exams, LANGCHAIN_CONFIG['CACHE_TTL'])
                    return exams
            
            # Fallback: dados diretos do banco
            from rag_agent.serializers import ExameSerializer
            exames = Exame.objects.all()
            data = ExameSerializer(exames, many=True).data
            cache.set(cache_key, data, LANGCHAIN_CONFIG['CACHE_TTL'])
            return data
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao obter exames: {e}")
            return []
    
    def get_specialties(self, query: str = None) -> List[Dict[str, Any]]:
        """
        Obt√©m especialidades com busca sem√¢ntica
        
        Args:
            query: Consulta de busca
            
        Returns:
            Lista de especialidades
        """
        cache_key = f"langchain_specialties_{query or 'all'}"
        cached_data = cache.get(cache_key)
        
        if cached_data:
            return cached_data
        
        try:
            if query:
                # Busca sem√¢ntica
                results = self.search(query, k=5)
                specialty_docs = [r for r in results if r['metadata'].get('type') == 'especialidade']
                
                if specialty_docs:
                    specialties = []
                    for doc in specialty_docs:
                        specialties.append({
                            'content': doc['content'],
                            'metadata': doc['metadata'],
                            'relevance': doc['relevance']
                        })
                    
                    cache.set(cache_key, specialties, LANGCHAIN_CONFIG['CACHE_TTL'])
                    return specialties
            
            # Fallback: dados diretos do banco
            from rag_agent.serializers import EspecialidadeSerializer
            especialidades = Especialidade.objects.filter(ativa=True)
            data = EspecialidadeSerializer(especialidades, many=True).data
            cache.set(cache_key, data, LANGCHAIN_CONFIG['CACHE_TTL'])
            return data
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao obter especialidades: {e}")
            return []
    
    def refresh_vectorstore(self):
        """Atualiza o vector store com dados mais recentes"""
        try:
            logger.info("üîÑ Atualizando vector store...")
            self._create_vectorstore()
            logger.info("‚úÖ Vector store atualizado com sucesso")
        except Exception as e:
            logger.error(f"‚ùå Erro ao atualizar vector store: {e}")
    
    def get_stats(self) -> Dict[str, Any]:
        """Retorna estat√≠sticas do vector store"""
        try:
            if not self.vectorstore:
                return {'status': 'not_initialized'}
            
            # Contar documentos por tipo
            stats = {
                'total_documents': self.vectorstore.index.ntotal,
                'embedding_dimension': self.vectorstore.index.d,
                'status': 'active'
            }
            
            return stats
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao obter estat√≠sticas: {e}")
            return {'status': 'error', 'error': str(e)}


# Inst√¢ncia global do servi√ßo
langchain_rag_service = LangChainRAGService()
