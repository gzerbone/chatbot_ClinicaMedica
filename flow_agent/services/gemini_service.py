"""
Serviﾃｧo de integraﾃｧﾃ｣o com Google Gemini AI
"""
import json
import logging
from typing import Any, Dict, List, Optional

import google.generativeai as genai
from django.conf import settings

logger = logging.getLogger(__name__)


class GeminiService:
    """
    Serviﾃｧo para integraﾃｧﾃ｣o com Google Gemini AI
    """
    
    def __init__(self):
        self.api_key = getattr(settings, 'GEMINI_API_KEY', '')
        
        # Verificar se Gemini estﾃ｡ habilitado
        self.enabled = getattr(settings, 'GEMINI_ENABLED', True)
        
        if not self.api_key:
            logger.warning("GEMINI_API_KEY nﾃ｣o configurada nas settings")
            self.enabled = False
        
        if not self.enabled:
            logger.warning("Gemini AI estﾃ｡ desabilitado nas configuraﾃｧﾃｵes")
            return
        
        # Configurar o Gemini apenas se habilitado e com API key
        try:
            genai.configure(api_key=self.api_key)
        except Exception as e:
            logger.error(f"Erro ao configurar Gemini: {e}")
            self.enabled = False
        
        # Obter configuraﾃｧﾃｵes do Django
        model_name = getattr(settings, 'GEMINI_MODEL', 'gemini-1.5-flash')
        temperature = getattr(settings, 'GEMINI_TEMPERATURE', 0.7)
        max_tokens = getattr(settings, 'GEMINI_MAX_TOKENS', 1024)
        
        self.model = genai.GenerativeModel(model_name)
        
        # Configuraﾃｧﾃｵes de geraﾃｧﾃ｣o
        self.generation_config = {
            "temperature": temperature,
            "top_p": 0.8,
            "top_k": 40,
            "max_output_tokens": max_tokens,
        }
    
    def generate_response(self, 
                         user_message: str, 
                         intent: str, 
                         context: Dict = None,
                         clinic_data: Dict = None) -> str:
        """
        Gera uma resposta usando o Gemini AI baseada na mensagem do usuﾃ｡rio,
        intenﾃｧﾃ｣o detectada e contexto da clﾃｭnica.
        
        Args:
            user_message: Mensagem original do usuﾃ｡rio
            intent: Intenﾃｧﾃ｣o detectada pelo sistema
            context: Contexto da conversa
            clinic_data: Dados da clﾃｭnica (mﾃｩdicos, especialidades, etc.)
            
        Returns:
            Resposta gerada pelo Gemini
        """
        # Se o Gemini nﾃ｣o estﾃ｡ habilitado ou configurado, usar resposta de fallback
        if not self.enabled or not hasattr(self, 'model'):
            logger.warning("Gemini nﾃ｣o disponﾃｭvel, usando resposta de fallback")
            return self._get_fallback_response(intent)
            
        try:
            # Construir prompt baseado na intenﾃｧﾃ｣o e contexto
            prompt = self._build_prompt(user_message, intent, context, clinic_data)
            
            # Gerar resposta
            response = self.model.generate_content(
                prompt,
                generation_config=self.generation_config
            )
            
            return response.text.strip()
            
        except Exception as e:
            logger.error(f"Erro ao gerar resposta com Gemini: {e}")
            return self._get_fallback_response(intent)
    
    def _build_prompt(self, 
                     user_message: str, 
                     intent: str, 
                     context: Dict = None,
                     clinic_data: Dict = None) -> str:
        """
        Constrﾃｳi o prompt para o Gemini baseado no contexto
        """
        # Prompt base do sistema
        # Buscar nome da clﾃｭnica dinamicamente do banco de dados
        clinic_name = "clﾃｭnica mﾃｩdica"  # valor padrﾃ｣o
        if clinic_data and 'nome' in clinic_data:
            clinic_name = clinic_data['nome']

        
        system_prompt = f"""Vocﾃｪ ﾃｩ um assistente virtual especializado da {clinic_name}. 
        Seu papel ﾃｩ ajudar pacientes com informaﾃｧﾃｵes sobre a clﾃｭnica, agendamentos, mﾃｩdicos e exames.
        
        IMPORTANTE:
        - Seja sempre cordial, profissional e prestativo
        - Use emojis moderadamente para tornar a conversa mais amigﾃ｡vel
        - Mantenha respostas concisas e diretas
        - Nﾃグ mencione telefone ou WhatsApp da clﾃｭnica a menos que o paciente peﾃｧa especificamente
        - Nﾃグ repita informaﾃｧﾃｵes de contato em cada resposta
        - Foque apenas no que o paciente perguntou
        - Se nﾃ｣o souber algo especﾃｭfico, oriente o paciente a entrar em contato
        - Sempre mantenha o foco em saﾃｺde e bem-estar
        - Use linguagem clara e acessﾃｭvel
        
        Contexto da clﾃｭnica:"""
        
        # Adicionar informaﾃｧﾃｵes da clﾃｭnica se disponﾃｭveis
        if clinic_data:
            system_prompt += f"\n\nInformaﾃｧﾃｵes da clﾃｭnica:\n{json.dumps(clinic_data, indent=2, ensure_ascii=False)}"
        
        # Adicionar histﾃｳrico da conversa se disponﾃｭvel
        if context and 'conversation_history' in context:
            history = context['conversation_history']
            if history:
                system_prompt += "\n\nHistﾃｳrico recente da conversa:"
                for i, msg in enumerate(history, 1):
                    role = "Paciente" if msg.get('is_user', True) else "Assistente"
                    content = msg.get('content', '')[:100]  # Limitar tamanho
                    system_prompt += f"\n{i}. {role}: {content}"
        
        # Adicionar contexto adicional da conversa
        if context:
            # Remover histﾃｳrico do contexto para evitar duplicaﾃｧﾃ｣o
            context_copy = {k: v for k, v in context.items() if k != 'conversation_history'}
            if context_copy:
                system_prompt += f"\n\nContexto atual:\n{json.dumps(context_copy, indent=2, ensure_ascii=False)}"
        
        # Adicionar instruﾃｧﾃｵes especﾃｭficas baseadas na intenﾃｧﾃ｣o
        intent_instructions = self._get_intent_instructions(intent)
        system_prompt += f"\n\nInstruﾃｧﾃｵes especﾃｭficas para esta intenﾃｧﾃ｣o ({intent}):\n{intent_instructions}"
        
        # Adicionar lﾃｳgica para contatos
        contact_logic = self._get_contact_logic(intent, user_message)
        system_prompt += f"\n\nLﾃｳgica de contatos:\n{contact_logic}"
        
        # Adicionar a mensagem do usuﾃ｡rio
        system_prompt += f"\n\nMensagem do paciente: {user_message}\n\nResposta:"
        
        return system_prompt
    
    def _get_intent_instructions(self, intent: str) -> str:
        """
        Retorna instruﾃｧﾃｵes especﾃｭficas baseadas na intenﾃｧﾃ｣o detectada
        """
        instructions = {
            'saudacao': """
            - Cumprimente calorosamente o paciente
            - Apresente-se como assistente da clﾃｭnica
            - Pergunte como posso ajudar
            """,
            
            'buscar_especialidade': """
            - Explique brevemente o que a especialidade perguntada trata
            - Sugira agendamento se o paciente demonstrar interesse
            """,
            
            'buscar_medico': """
            - Apresente os mﾃｩdicos disponﾃｭveis que atendem a especialidade perguntada
            - Informe nome, especialidade, convﾃｪnios aceitos e horﾃ｡rios de atendimento
            - Informe preﾃｧo da consulta particular se relevante
            - Se houver mais de um mﾃｩdico, pergunte qual deseja agendar
            - Nﾃグ mencione telefone/WhatsApp a menos que o paciente peﾃｧa
            """,
            
            'buscar_exame': """
            - Explique o que ﾃｩ o exame de forma clara
            - Detalhe como funciona o procedimento
            - Mencione preparaﾃｧﾃ｣o necessﾃ｡ria
            - Informe preﾃｧo e duraﾃｧﾃ｣o
            - Destaque benefﾃｭcios do exame
            """,
            
            'buscar_info_clinica': """
            - Forneﾃｧa APENAS as informaﾃｧﾃｵes especﾃｭficas que o paciente perguntou
            - Se perguntar sobre endereﾃｧo, forneﾃｧa apenas o endereﾃｧo
            - Se perguntar sobre telefone, forneﾃｧa apenas o telefone
            - Se perguntar sobre horﾃ｡rios, forneﾃｧa apenas os horﾃ｡rios
            - Se perguntar sobre convﾃｪnios, liste apenas os convﾃｪnios aceitos por cada mﾃｩdico
            - Se perguntar sobre polﾃｭticas, explique apenas as polﾃｭticas da clﾃｭnica
            - Nﾃグ forneﾃｧa informaﾃｧﾃｵes nﾃ｣o solicitadas
            """,
            
            'agendar_consulta': """
            - Guie o paciente atravﾃｩs do processo de agendamento
            - Seja claro sobre as etapas necessﾃ｡rias
            - Seja claro sobre os horﾃ｡rios disponﾃｭveis
            - Seja claro sobre os mﾃｩdicos disponﾃｭveis
            - Seja claro sobre os exames disponﾃｭveis
            - Seja claro sobre os convﾃｪnios disponﾃｭveis
            - Seja claro sobre os preﾃｧos das consultas
            - Seja claro sobre os preﾃｧos dos exames
            - Seja claro sobre os planos de saﾃｺde aceitos por cada mﾃｩdico
            - Nﾃ｣o faﾃｧa um texto longo, faﾃｧa um texto curto e direto
            - Mantenha o processo organizado e fﾃ｡cil
            """,
            
            'confirmar_agendamento': """
            - Verifique agendamentos pendentes
            - Confirme informaﾃｧﾃｵes importantes como nome completo e telefone de contato do paciente
            - Oriente sobre prﾃｳximos passos
            - Tranquilize o paciente sobre o processo
            """,
            
            'cancelar_agendamento': """
            - Seja compreensivo e acolhedor
            - Facilite o processo de cancelamento, informando que o cancelamento deve ser feito pelo WhatsApp da clﾃｭnica ou pelo nﾃｺmero de telefone da clﾃｭnica
            - Sugira reagendamento se apropriado
            - Mantenha a porta aberta para futuras consultas
            """,
            
            'horarios_disponiveis': """
            - Apresente horﾃ｡rios de forma clara
            - Considere preferﾃｪncias do paciente
            - Sugira alternativas se necessﾃ｡rio
            - Facilite a escolha do horﾃ｡rio
            """,
            
            'despedida': """
            - Despeﾃｧa-se cordialmente
            - Reforce que estﾃ｡ disponﾃｭvel para ajudar
            - Deseje boa saﾃｺde
            - Convide para retornar quando necessﾃ｡rio
            """,
            
            'ajuda': """
            - Explique claramente como pode ajudar
            - Liste os principais serviﾃｧos
            - Oriente sobre como proceder
            - Seja proativo em oferecer ajuda
            """,
            
            'desconhecida': """
            - Seja educado ao nﾃ｣o entender
            - Peﾃｧa esclarecimentos de forma gentil
            - Ofereﾃｧa opﾃｧﾃｵes de como pode ajudar
            - Mantenha o tom acolhedor
            """
        }
        
        return instructions.get(intent, instructions['desconhecida'])
    
    def _get_contact_logic(self, intent: str, user_message: str) -> str:
        """
        Retorna lﾃｳgica especﾃｭfica para quando mostrar contatos da clﾃｭnica
        """
        message_lower = user_message.lower()
        
        # Palavras-chave que indicam necessidade de contato
        contact_keywords = [
            'telefone', 'whatsapp', 'contato', 'ligar', 'falar', 'agendar',
            'marcar', 'confirmar', 'disponibilidade', 'horﾃ｡rio', 'horarios'
        ]
        
        # Verificar se o paciente pediu contato especificamente
        asked_for_contact = any(keyword in message_lower for keyword in contact_keywords)
        
        # Intenﾃｧﾃｵes que geralmente precisam de contato
        contact_intents = ['agendar_consulta', 'confirmar_agendamento', 'buscar_info_clinica']
        
        if asked_for_contact or intent in contact_intents:
            return """
            - Se o paciente pediu telefone/WhatsApp, forneﾃｧa APENAS o que foi solicitado
            - Se o paciente quer agendar, forneﾃｧa contatos para agendamento
            - Se o paciente quer confirmar, forneﾃｧa contatos para confirmaﾃｧﾃ｣o
            - Seja especﾃｭfico: telefone para ligar, WhatsApp para mensagem
            """
        else:
            return """
            - Nﾃグ mencione telefone ou WhatsApp nesta resposta
            - Foque apenas no que o paciente perguntou
            - Se o paciente demonstrar interesse em agendar, aﾃｭ sim ofereﾃｧa contatos
            """
    
    def _get_fallback_response(self, intent: str) -> str:
        """
        Retorna uma resposta de fallback caso o Gemini falhe
        """
        fallback_responses = {
            'saudacao': "Olﾃ｡! 沽 Como posso ajudﾃ｡-lo hoje?",
            'buscar_especialidade': "Aqui estﾃ｣o nossas especialidades. Qual vocﾃｪ gostaria de conhecer?",
            'buscar_medico': "Aqui estﾃ｣o nossos mﾃｩdicos. Qual especialidade vocﾃｪ precisa?",
            'buscar_exame': "Posso fornecer informaﾃｧﾃｵes sobre nossos exames. Qual vocﾃｪ gostaria de conhecer?",
            'buscar_info_clinica': "Que informaﾃｧﾃ｣o vocﾃｪ precisa sobre a clﾃｭnica?",
            'agendar_consulta': "Vou ajudﾃ｡-lo a agendar. Qual especialidade vocﾃｪ precisa?",
            'confirmar_agendamento': "Vou verificar seus agendamentos.",
            'cancelar_agendamento': "Entendo que precisa cancelar. Como posso ajudar?",
            'horarios_disponiveis': "Vou verificar os horﾃ｡rios disponﾃｭveis.",
            'despedida': "Atﾃｩ logo! Foi um prazer ajudﾃ｡-lo! 沽",
            'ajuda': "Posso ajudﾃ｡-lo com informaﾃｧﾃｵes sobre mﾃｩdicos, exames e agendamentos.",
            'desconhecida': "Desculpe, nﾃ｣o entendi. Como posso ajudﾃ｡-lo?"
        }
        
        return fallback_responses.get(intent, fallback_responses['desconhecida'])
    
    def generate_contextual_response(self, 
                                   user_message: str,
                                   intent: str,
                                   conversation_history: List[Dict],
                                   clinic_data: Dict = None) -> str:
        """
        Gera resposta considerando o histﾃｳrico da conversa
        
        Args:
            user_message: Mensagem atual do usuﾃ｡rio
            intent: Intenﾃｧﾃ｣o detectada
            conversation_history: Histﾃｳrico da conversa
            clinic_data: Dados da clﾃｭnica
            
        Returns:
            Resposta contextualizada
        """
        try:
            # Construir contexto do histﾃｳrico
            history_context = self._build_conversation_context(conversation_history)
            
            # Construir prompt com histﾃｳrico
            prompt = self._build_contextual_prompt(
                user_message, intent, history_context, clinic_data
            )
            
            # Gerar resposta
            response = self.model.generate_content(
                prompt,
                generation_config=self.generation_config
            )
            
            return response.text.strip()
            
        except Exception as e:
            logger.error(f"Erro ao gerar resposta contextual: {e}")
            return self.generate_response(user_message, intent, clinic_data=clinic_data)
    
    def _build_conversation_context(self, history: List[Dict]) -> str:
        """
        Constrﾃｳi contexto a partir do histﾃｳrico da conversa
        """
        if not history:
            return "Primeira interaﾃｧﾃ｣o com o paciente."
        
        context = "Histﾃｳrico da conversa:\n"
        for i, msg in enumerate(history[-5:], 1):  # ﾃ嗟timas 5 mensagens
            role = "Paciente" if msg.get('tipo') == 'entrada' else "Assistente"
            content = msg.get('conteudo', '')
            context += f"{i}. {role}: {content}\n"
        
        return context
    
    def _build_contextual_prompt(self, 
                               user_message: str,
                               intent: str,
                               history_context: str,
                               clinic_data: Dict = None) -> str:
        """
        Constrﾃｳi prompt considerando o histﾃｳrico da conversa
        """
        system_prompt = """Vocﾃｪ ﾃｩ um assistente virtual especializado de uma clﾃｭnica mﾃｩdica.
        Considere o histﾃｳrico da conversa para dar respostas mais personalizadas e contextuais.
        
        IMPORTANTE:
        - Use o histﾃｳrico para entender melhor o que o paciente precisa
        - Mantenha consistﾃｪncia com respostas anteriores
        - Seja proativo baseado no contexto da conversa
        - Continue fluxos de agendamento ou consultas de forma natural
        """
        
        if clinic_data:
            system_prompt += f"\n\nInformaﾃｧﾃｵes da clﾃｭnica:\n{json.dumps(clinic_data, indent=2, ensure_ascii=False)}"
        
        system_prompt += f"\n\n{history_context}"
        
        intent_instructions = self._get_intent_instructions(intent)
        system_prompt += f"\n\nInstruﾃｧﾃｵes para esta intenﾃｧﾃ｣o ({intent}):\n{intent_instructions}"
        
        system_prompt += f"\n\nMensagem atual do paciente: {user_message}\n\nResposta:"
        
        return system_prompt
    
    def test_connection(self) -> bool:
        """
        Testa a conexﾃ｣o com o Gemini AI
        
        Returns:
            True se a conexﾃ｣o estiver funcionando
        """
        if not self.enabled or not hasattr(self, 'model'):
            logger.warning("Gemini nﾃ｣o estﾃ｡ configurado para teste")
            return False
            
        try:
            test_response = self.model.generate_content(
                "Teste de conexﾃ｣o. Responda apenas 'OK'.",
                generation_config={"max_output_tokens": 10}
            )
            return "ok" in test_response.text.lower()
        except Exception as e:
            logger.error(f"Erro ao testar conexﾃ｣o com Gemini: {e}")
            return False
