"""
Servi√ßo de integra√ß√£o com Google Gemini AI
"""
import json
import logging
from typing import Any, Dict, List, Optional

import google.generativeai as genai
from django.conf import settings

logger = logging.getLogger(__name__)


class GeminiService:
    """
    Servi√ßo para integra√ß√£o com Google Gemini AI
    """
    
    def __init__(self):
        self.api_key = getattr(settings, 'GEMINI_API_KEY', '')
        
        # Verificar se Gemini est√° habilitado
        self.enabled = getattr(settings, 'GEMINI_ENABLED', True)
        
        if not self.api_key:
            logger.warning("GEMINI_API_KEY n√£o configurada nas settings")
            self.enabled = False
        
        if not self.enabled:
            logger.warning("Gemini AI est√° desabilitado nas configura√ß√µes")
            return
        
        # Configurar o Gemini apenas se habilitado e com API key
        try:
            genai.configure(api_key=self.api_key)
        except Exception as e:
            logger.error(f"Erro ao configurar Gemini: {e}")
            self.enabled = False
        
        # Obter configura√ß√µes do Django
        model_name = getattr(settings, 'GEMINI_MODEL', 'gemini-1.5-flash')
        temperature = getattr(settings, 'GEMINI_TEMPERATURE', 0.7)
        max_tokens = getattr(settings, 'GEMINI_MAX_TOKENS', 1024)
        
        self.model = genai.GenerativeModel(model_name)
        
        # Configura√ß√µes de gera√ß√£o
        self.generation_config = {
            "temperature": temperature,
            "top_p": 0.8,
            "top_k": 40,
            "max_output_tokens": max_tokens,
        }
    
    def generate_response(self, 
                         user_message: str, 
                         intent: str, 
                         context: Dict = None,
                         clinic_data: Dict = None) -> str:
        """
        Gera uma resposta usando o Gemini AI baseada na mensagem do usu√°rio,
        inten√ß√£o detectada e contexto da cl√≠nica.
        
        Args:
            user_message: Mensagem original do usu√°rio
            intent: Inten√ß√£o detectada pelo sistema
            context: Contexto da conversa
            clinic_data: Dados da cl√≠nica (m√©dicos, especialidades, etc.)
            
        Returns:
            Resposta gerada pelo Gemini
        """
        # Se o Gemini n√£o est√° habilitado ou configurado, usar resposta de fallback
        if not self.enabled or not hasattr(self, 'model'):
            logger.warning("Gemini n√£o dispon√≠vel, usando resposta de fallback")
            return self._get_fallback_response(intent)
            
        try:
            # Construir prompt baseado na inten√ß√£o e contexto
            prompt = self._build_prompt(user_message, intent, context, clinic_data)
            
            # Gerar resposta
            response = self.model.generate_content(
                prompt,
                generation_config=self.generation_config
            )
            
            return response.text.strip()
            
        except Exception as e:
            logger.error(f"Erro ao gerar resposta com Gemini: {e}")
            return self._get_fallback_response(intent)
    
    def _build_prompt(self, 
                     user_message: str, 
                     intent: str, 
                     context: Dict = None,
                     clinic_data: Dict = None) -> str:
        """
        Constr√≥i o prompt para o Gemini baseado no contexto
        """
        # Prompt base do sistema
        # Buscar nome da cl√≠nica dinamicamente do banco de dados
        clinic_name = "cl√≠nica m√©dica"  # valor padr√£o
        if clinic_data and 'nome' in clinic_data:
            clinic_name = clinic_data['nome']
        elif clinic_data and 'name' in clinic_data:
            clinic_name = clinic_data['name']
        
        system_prompt = f"""Voc√™ √© um assistente virtual especializado da {clinic_name}. 
        Seu papel √© ajudar pacientes com informa√ß√µes sobre a cl√≠nica, agendamentos, m√©dicos e exames.
        
        IMPORTANTE:
        - Seja sempre cordial, profissional e prestativo
        - Use emojis moderadamente para tornar a conversa mais amig√°vel
        - Mantenha respostas concisas mas informativas
        - Se n√£o souber algo espec√≠fico, oriente o paciente a entrar em contato com o n√∫mero da cl√≠nica. 
        - Sempre mantenha o foco em sa√∫de e bem-estar
        - Use linguagem clara e acess√≠vel
        
        Contexto da cl√≠nica:"""
        
        # Adicionar informa√ß√µes da cl√≠nica se dispon√≠veis
        if clinic_data:
            system_prompt += f"\n\nInforma√ß√µes da cl√≠nica:\n{json.dumps(clinic_data, indent=2, ensure_ascii=False)}"
        
        # Adicionar contexto da conversa
        if context:
            system_prompt += f"\n\nContexto da conversa:\n{json.dumps(context, indent=2, ensure_ascii=False)}"
        
        # Adicionar instru√ß√µes espec√≠ficas baseadas na inten√ß√£o
        intent_instructions = self._get_intent_instructions(intent)
        system_prompt += f"\n\nInstru√ß√µes espec√≠ficas para esta inten√ß√£o ({intent}):\n{intent_instructions}"
        
        # Adicionar a mensagem do usu√°rio
        system_prompt += f"\n\nMensagem do paciente: {user_message}\n\nResposta:"
        
        return system_prompt
    
    def _get_intent_instructions(self, intent: str) -> str:
        """
        Retorna instru√ß√µes espec√≠ficas baseadas na inten√ß√£o detectada
        """
        instructions = {
            'saudacao': """
            - Cumprimente calorosamente o paciente
            - Apresente-se como assistente da cl√≠nica
            - Ofere√ßa ajuda com informa√ß√µes sobre a cl√≠nica
            - Mencione os principais servi√ßos dispon√≠veis
            """,
            
            'buscar_especialidade': """
            - Liste as especialidades dispon√≠veis de forma organizada
            - Explique brevemente o que cada especialidade trata
            - Sugira agendamento se o paciente demonstrar interesse
            """,
            
            'buscar_medico': """
            - Apresente os m√©dicos dispon√≠veis
            - Inclua especialidades, experi√™ncia e formas de pagamento
            - Destaque pontos fortes de cada m√©dico
            - Facilite o processo de escolha
            """,
            
            'buscar_exame': """
            - Explique o que √© o exame de forma clara
            - Detalhe como funciona o procedimento
            - Mencione prepara√ß√£o necess√°ria
            - Informe pre√ßo e dura√ß√£o
            - Destaque benef√≠cios do exame
            """,
            
            'buscar_info_clinica': """
            - Forne√ßa informa√ß√µes completas da cl√≠nica
            - Inclua endere√ßo, telefone, hor√°rios
            - Mencione pol√≠ticas de agendamento
            - Destaque diferenciais da cl√≠nica
            """,
            
            'agendar_consulta': """
            - Guie o paciente atrav√©s do processo de agendamento
            - Seja claro sobre as etapas necess√°rias
            - Confirme informa√ß√µes importantes
            - Mantenha o processo organizado e f√°cil
            """,
            
            'confirmar_agendamento': """
            - Verifique agendamentos pendentes
            - Confirme detalhes importantes
            - Oriente sobre pr√≥ximos passos
            - Tranquilize o paciente sobre o processo
            """,
            
            'cancelar_agendamento': """
            - Seja compreensivo e acolhedor
            - Facilite o processo de cancelamento
            - Sugira reagendamento se apropriado
            - Mantenha a porta aberta para futuras consultas
            """,
            
            'horarios_disponiveis': """
            - Apresente hor√°rios de forma clara
            - Considere prefer√™ncias do paciente
            - Sugira alternativas se necess√°rio
            - Facilite a escolha do hor√°rio
            """,
            
            'despedida': """
            - Despe√ßa-se cordialmente
            - Reforce que est√° dispon√≠vel para ajudar
            - Deseje boa sa√∫de
            - Convide para retornar quando necess√°rio
            """,
            
            'ajuda': """
            - Explique claramente como pode ajudar
            - Liste os principais servi√ßos
            - Oriente sobre como proceder
            - Seja proativo em oferecer ajuda
            """,
            
            'desconhecida': """
            - Seja educado ao n√£o entender
            - Pe√ßa esclarecimentos de forma gentil
            - Ofere√ßa op√ß√µes de como pode ajudar
            - Mantenha o tom acolhedor
            """
        }
        
        return instructions.get(intent, instructions['desconhecida'])
    
    def _get_fallback_response(self, intent: str) -> str:
        """
        Retorna uma resposta de fallback caso o Gemini falhe
        """
        fallback_responses = {
            'saudacao': "Ol√°! Bem-vindo √† cl√≠nica! üòä Como posso ajud√°-lo hoje?",
            'buscar_especialidade': "Aqui est√£o nossas especialidades dispon√≠veis. Gostaria de mais informa√ß√µes sobre alguma espec√≠fica?",
            'buscar_medico': "Aqui est√£o nossos m√©dicos. Posso ajud√°-lo a escolher o mais adequado para sua necessidade.",
            'buscar_exame': "Posso fornecer informa√ß√µes sobre nossos exames. Qual exame voc√™ gostaria de conhecer?",
            'buscar_info_clinica': "Aqui est√£o as informa√ß√µes da nossa cl√≠nica. Como posso ajud√°-lo?",
            'agendar_consulta': "Vou ajud√°-lo a agendar sua consulta. Vamos come√ßar?",
            'confirmar_agendamento': "Vou verificar seus agendamentos. Um momento, por favor.",
            'cancelar_agendamento': "Entendo que precisa cancelar. Vou ajud√°-lo com isso.",
            'horarios_disponiveis': "Vou verificar os hor√°rios dispon√≠veis para voc√™.",
            'despedida': "At√© logo! Foi um prazer ajud√°-lo! üòä",
            'ajuda': "Posso ajud√°-lo com informa√ß√µes sobre nossa cl√≠nica, agendamentos e m√©dicos.",
            'desconhecida': "Desculpe, n√£o entendi bem. Como posso ajud√°-lo hoje?"
        }
        
        return fallback_responses.get(intent, fallback_responses['desconhecida'])
    
    def generate_contextual_response(self, 
                                   user_message: str,
                                   intent: str,
                                   conversation_history: List[Dict],
                                   clinic_data: Dict = None) -> str:
        """
        Gera resposta considerando o hist√≥rico da conversa
        
        Args:
            user_message: Mensagem atual do usu√°rio
            intent: Inten√ß√£o detectada
            conversation_history: Hist√≥rico da conversa
            clinic_data: Dados da cl√≠nica
            
        Returns:
            Resposta contextualizada
        """
        try:
            # Construir contexto do hist√≥rico
            history_context = self._build_conversation_context(conversation_history)
            
            # Construir prompt com hist√≥rico
            prompt = self._build_contextual_prompt(
                user_message, intent, history_context, clinic_data
            )
            
            # Gerar resposta
            response = self.model.generate_content(
                prompt,
                generation_config=self.generation_config
            )
            
            return response.text.strip()
            
        except Exception as e:
            logger.error(f"Erro ao gerar resposta contextual: {e}")
            return self.generate_response(user_message, intent, clinic_data=clinic_data)
    
    def _build_conversation_context(self, history: List[Dict]) -> str:
        """
        Constr√≥i contexto a partir do hist√≥rico da conversa
        """
        if not history:
            return "Primeira intera√ß√£o com o paciente."
        
        context = "Hist√≥rico da conversa:\n"
        for i, msg in enumerate(history[-5:], 1):  # √öltimas 5 mensagens
            role = "Paciente" if msg.get('tipo') == 'entrada' else "Assistente"
            content = msg.get('conteudo', '')
            context += f"{i}. {role}: {content}\n"
        
        return context
    
    def _build_contextual_prompt(self, 
                               user_message: str,
                               intent: str,
                               history_context: str,
                               clinic_data: Dict = None) -> str:
        """
        Constr√≥i prompt considerando o hist√≥rico da conversa
        """
        system_prompt = """Voc√™ √© um assistente virtual especializado de uma cl√≠nica m√©dica.
        Considere o hist√≥rico da conversa para dar respostas mais personalizadas e contextuais.
        
        IMPORTANTE:
        - Use o hist√≥rico para entender melhor o que o paciente precisa
        - Mantenha consist√™ncia com respostas anteriores
        - Seja proativo baseado no contexto da conversa
        - Continue fluxos de agendamento ou consultas de forma natural
        """
        
        if clinic_data:
            system_prompt += f"\n\nInforma√ß√µes da cl√≠nica:\n{json.dumps(clinic_data, indent=2, ensure_ascii=False)}"
        
        system_prompt += f"\n\n{history_context}"
        
        intent_instructions = self._get_intent_instructions(intent)
        system_prompt += f"\n\nInstru√ß√µes para esta inten√ß√£o ({intent}):\n{intent_instructions}"
        
        system_prompt += f"\n\nMensagem atual do paciente: {user_message}\n\nResposta:"
        
        return system_prompt
    
    def test_connection(self) -> bool:
        """
        Testa a conex√£o com o Gemini AI
        
        Returns:
            True se a conex√£o estiver funcionando
        """
        if not self.enabled or not hasattr(self, 'model'):
            logger.warning("Gemini n√£o est√° configurado para teste")
            return False
            
        try:
            test_response = self.model.generate_content(
                "Teste de conex√£o. Responda apenas 'OK'.",
                generation_config={"max_output_tokens": 10}
            )
            return "ok" in test_response.text.lower()
        except Exception as e:
            logger.error(f"Erro ao testar conex√£o com Gemini: {e}")
            return False
